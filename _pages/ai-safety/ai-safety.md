---
layout: single
title: AI Safety
permalink: ai-safety/ai-safety/
---
On this page, the resources I liked the most are listed.

# Theory
- [https://aisafetyfundamentals.com/](https://aisafetyfundamentals.com/) (2023)

# Organizations
- [https://aisafety.world/](https://aisafety.world/) (2023)

# Technical tools

## Explainability
- [Explabox](https://github.com/MarcelRobeer/explabox) (2022)
- [IBM: AIX360](https://github.com/Trusted-AI/AIX360) (2019)

## Fairness
- [IBM: Fairness 360](https://www.ibm.com/opensource/open/projects/ai-fairness-360/)

## Adversarial robustness
- [IBM: ART](https://github.com/Trusted-AI/adversarial-robustness-toolbox) (2018)
- [IBM: URET](https://github.com/IBM/URET) (2023)
    - [Paper](https://arxiv.org/pdf/2308.01840.pdf)

# MLOps
## Model repositories
- [IBM: Factsheets](https://aifs360.res.ibm.com/) 


## Platforms
- [wandb.ai](https://wandb.ai/site)
- [run.ai](https://www.run.ai/)
- [mlflow.org](https://mlflow.org/)
- [kubeflow.org](https://www.kubeflow.org/)